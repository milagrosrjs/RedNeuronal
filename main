import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import regularizers

def assign_label(average):
    if average >= 90:
        return 0
    elif average >= 80:
        return 1
    elif average >= 70:
        return 2
    else:
        return 3

def calculate_percentage(grade, max_grade=100):
    return (grade / max_grade) * 100

def train_area_model(area_data):
    area_data = np.array(area_data)
    X_area = area_data[:, :-1]
    y_area = area_data[:, -1] # Resta 1 a las etiquetas de las áreas
    if np.min(y_area) == 1:
         y_area = y_area - 1
    X_train_area, X_test_area, y_train_area, y_test_area = train_test_split(X_area, y_area, test_size=0.2, random_state=42)

    scaler_area = StandardScaler()
    X_train_area = scaler_area.fit_transform(X_train_area)
    X_test_area = scaler_area.transform(X_test_area)

    model_area = keras.Sequential([
        keras.layers.Dense(64, activation='tanh', input_shape=(X_train_area.shape[1],)),
        keras.layers.Dense(32, activation='tanh'),
        keras.layers.Dense(5, activation='softmax')
    ])

    model_area.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    model_area.fit(X_train_area, y_train_area, epochs=100, validation_split=0.25)

    return model_area, scaler_area

def predict_best_area(subject_grades, area_models, area_scalers):
    subject_names = ["Introducción", "Álgebra", "Química", "Sistemas", "Inglés"]
    area_messages = [
        "según su desempeño, su mejor área es la programación",
        "según su rendimiento, el área de matemáticas/números es su fuerte",
        "su mejor desempeño, el área de química es su fuerte",
        "su área recomendada es Gestión de proyectos",
        "su área recomendada es el de las lenguas extranjeras"
    ]

    predictions = []
    for i, model in enumerate(area_models):
        scaled_data = area_scalers[i].transform([subject_grades])
        prediction = model.predict(scaled_data)
        predictions.append(prediction)

    # Find the index of the best area
    max_values = [np.max(prediction) for prediction in predictions]
    best_area_index = np.argmax(max_values)

    # Find the index of the highest grade
    highest_grade_index = np.argmax(subject_grades)

    # Check if the best area index matches the highest grade index
    if best_area_index == highest_grade_index:
        return area_messages[best_area_index], predictions[best_area_index] + 1
    else:
        return area_messages[highest_grade_index], predictions[highest_grade_index] + 1

areas = [
    # Datos del área de Introducción
    [   
        [80, 70, 71, 72, 73, 0],
        [81, 71, 72, 73, 74, 0],
        [82, 72, 73, 74, 75, 0],
        [83, 73, 74, 75, 76, 0],
        [84, 74, 75, 76, 77, 0],
        [85, 75, 76, 77, 78, 0],
        [86, 76, 77, 78, 79, 0],
        [87, 77, 78, 79, 80, 0],
        [88, 78, 79, 80, 81, 0],
        [89, 79, 80, 81, 82, 0],
        [90, 80, 81, 82, 83, 0],
        [91, 81, 82, 83, 84, 0],
        [92, 82, 83, 84, 85, 0],
        [93, 83, 84, 85, 86, 0],
        [94, 84, 85, 86, 87, 0],
        [95, 85, 86, 87, 88, 0],
        [96, 86, 87, 88, 89, 0],
        [97, 87, 88, 89, 90, 0],
        [98, 88, 89, 90, 91, 0],
        [99, 89, 90, 91, 92, 0],
    ],
    # Datos del área de Álgebra
    [
        [79, 90, 72, 60, 64, 1],
        [80, 89, 73, 61, 65, 1],
        [81, 88, 74, 62, 66, 1],
        [82, 87, 75, 63, 67, 1],
        [83, 86, 76, 64, 68, 1],
        [84, 85, 77, 65, 69, 1],
        [85, 84, 78, 66, 70, 1],
        [86, 83, 79, 67, 71, 1],
        [87, 82, 80, 68, 72, 1],
        [88, 81, 81, 69, 73, 1],
        [89, 80, 82, 70, 74, 1],
        [90, 79, 83, 71, 75, 1],
        [91, 78, 84, 72, 76, 1],
        [92, 77, 85, 73, 77, 1],
        [93, 76, 86, 74, 78, 1],
    ],
    # Datos del área de Química
    [
        [79, 90, 72, 60, 64, 1],
        [80, 89, 73, 61, 65, 1],
        [81, 88, 74, 62, 66, 1],
        [82, 87, 75, 63, 67, 1],
        [83, 86, 76, 64, 68, 1],
        [84, 85, 77, 65, 69, 1],
        [85, 84, 78, 66, 70, 1],
        [86, 83, 79, 67, 71, 1],
        [87, 82, 80, 68, 72, 1],
        [88, 81, 81, 69, 73, 1],
        [89, 80, 82, 70, 74, 1],
        [90, 79, 83, 71, 75, 1],
        [91, 78, 84, 72, 76, 1],
        [92, 77, 85, 73, 77, 1],
        [93, 76, 86, 74, 78, 1],
    ],
    # Datos del área de Sistemas
    [
        [71, 63, 75, 80, 75, 3],
        [72, 64, 76, 81, 76, 3],
        [73, 65, 77, 82, 77, 3],
        [74, 66, 78, 83, 78, 3],
        [75, 67, 79, 84, 79, 3],
        [76, 68, 80, 85, 80, 3],
        [77, 69, 75, 86, 81, 3],
        [78, 70, 76, 87, 82, 3],
        [79, 71, 77, 88, 83, 3],
        [80, 72, 78, 89, 84, 3],
        [81, 73, 79, 90, 85, 3],
        [82, 74, 80, 91, 86, 3],
        [83, 75, 81, 92, 87, 3],
        [84, 76, 82, 93, 88, 3],
        [85, 77, 83, 94, 89, 3],
        [86, 78, 84, 95, 90, 3],
        [87, 79, 85, 96, 91, 3],
    ],
    # Datos del área de Inglés
    [
        [71, 63, 75, 80, 75, 3],
        [72, 64, 76, 81, 76, 3],
        [73, 65, 77, 82, 77, 3],
        [74, 66, 78, 83, 78, 3],
        [75, 67, 79, 84, 79, 3],
        [76, 68, 80, 85, 80, 3],
        [77, 69, 75, 86, 81, 3],
        [78, 70, 76, 87, 82, 3],
        [79, 71, 77, 88, 83, 3],
        [80, 72, 78, 89, 84, 3],
        [81, 73, 79, 90, 85, 3],
        [82, 74, 80, 91, 86, 3],
        [83, 75, 81, 92, 87, 3],
        [84, 76, 82, 93, 88, 3],
        [85, 77, 83, 94, 89, 3],
        [86, 78, 84, 95, 90, 3],
        [87, 79, 85, 96, 91, 3],
    ],
]
# Entrenar un modelo para cada área
intro_model, intro_scaler = train_area_model(areas[0])
algebra_model, algebra_scaler = train_area_model(areas[1])
quimica_model, quimica_scaler = train_area_model(areas[2])
sistemas_model, sistemas_scaler = train_area_model(areas[3])
ingles_model, ingles_scaler = train_area_model(areas[4])

# Cargar los datos
data = np.array([
    [90, 90, 90, 90, 90, 0],
    [91, 91, 92, 91, 91, 0],
    [92, 93, 92, 93, 94, 0],
    [95, 95, 95, 95, 95, 0],
    [98, 90, 95, 96, 98, 0],
    [98, 90, 94, 92, 91, 0],
    [91, 82, 83, 94, 94, 0],
    [92, 81, 82, 93, 93, 0],
    [94, 81, 86, 92, 96, 0],
    [90, 87, 85, 97, 97, 0],
    [98, 80, 86, 97, 93, 0],
    [98, 88, 88, 98, 98, 0],
    [99, 89, 89, 99, 99, 0],
    [96, 86, 86, 94, 93, 0],
    [90, 80, 80, 90, 90, 0],
    [80, 80, 80, 90, 90, 1],
    [81, 82, 83, 91, 92, 1],
    [82, 84, 84, 94, 92, 1],
    [80, 80, 83, 93, 92, 1],
    [80, 80, 81, 82, 82, 1],
    [83, 82, 81, 82, 82, 1],
    [79, 80, 82, 82, 84, 1],
    [77, 81, 82, 82, 83, 1],
    [76, 82, 84, 83, 83, 1],
    [78, 83, 83, 81, 81, 1],
    [79, 81, 82, 82, 80, 1],
    [80, 80, 80, 80, 80, 1],
    [70, 70, 70, 70, 70, 2],
    [75, 75, 70, 70, 70, 2],
    [74, 73, 74, 72, 74, 2],
    [75, 74, 76, 77, 71, 2],
    [78, 75, 73, 73, 73, 2],
    [71, 78, 79, 72, 79, 2],
    [70, 70, 70, 70, 70, 2],
    [71, 71, 71, 71, 71, 2],
    [72, 72, 73, 72, 74, 2],
    [73, 71, 71, 73, 73, 2],
    [72, 72, 73, 74, 75, 2],
    [74, 72, 71, 73, 71, 2],
    [60, 60, 60, 60, 60, 3],
    [65, 60, 65, 60, 65, 3],
    [62, 61, 62, 63, 64, 3],
    [63, 64, 63, 62, 65, 3],
    [61, 64, 62, 65, 61, 3],
    [65, 64, 64, 63, 63, 3],
    [63, 63, 63, 63, 62, 3],
    [64, 62, 61, 65, 65, 3],
    [64, 66, 66, 62, 61, 3],
    [61, 61, 61, 63, 62, 3],
    [64, 62, 65, 64, 64, 3],
    [61, 62, 62, 61, 61, 3]
])

# Calcular el promedio de las notas y asignar etiquetas
averages = np.mean(data[:, :-1], axis=1)
labels = np.array([assign_label(avg) for avg in averages])
data[:, -1] = labels

# Dividir los datos en características (X) y etiquetas (y)
X = data[:, :-1]
y = data[:, -1]

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar los datos de entrada
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Definir la arquitectura del modelo
model = keras.Sequential([
    keras.layers.Dense(64, activation='tanh', input_shape=(X_train.shape[1],)),
    keras.layers.Dense(32, activation='tanh'),
    keras.layers.Dense(4, activation='softmax')
])

# Compilar el modelo
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Ajustar el modelo con más épocas y utilizar técnicas de regularización
model.fit(X_train, y_train, epochs=100, validation_split=0.25)

# Evaluar el rendimiento en los datos de prueba
_, test_accuracy = model.evaluate(X_test, y_test)
print("Rendimiento en los datos de prueba:", test_accuracy)

def get_float_input(prompt):
    while True:
        try:
            value = float(input(prompt))
            return value
        except ValueError:
            print("Por favor, ingrese un número válido.")

# Realizar una predicción con nuevos datos
print("Ingrese las notas del alumno:")
introduccion = get_float_input("Nota de Introduccion: ")
algebra = get_float_input("Nota de Algebra: ")
quimica = get_float_input("Nota de Quimica: ")
sistemas = get_float_input("Nota de Semas: ")
ingles = get_float_input("Nota de Ingles: ")

# Definir los nombres de las clases de rendimiento
performance_class_names = ['Excelente', 'Bueno', 'Regular', 'Insuficiente']

# Real la predicción de rendimiento y área recomendada
new_data = scaler.transform([[introduccion, algebra, quimica, sistemas, ingles]])
prediction = model.predict(new_data)
predicted_class = np.argmax(prediction)
predicted_performance_class_name = performance_class_names[predicted_class]

# Crear una lista de modelos y escaladores de áreas
area_models = [intro_model, algebra_model, quimica_model, sistemas_model, ingles_model]
area_scalers = [intro_scaler, algebra_scaler, quimica_scaler, sistemas_scaler, ingles_scaler]

best_area_message, best_area_prediction = predict_best_area([introduccion, algebra, quimica, sistemas, ingles], area_models, area_scalers)

print("El rendimiento del alumno es:", predicted_performance_class_name)
print(f"Jovencito/a {best_area_message}.")